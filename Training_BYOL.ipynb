{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"z8-Ivaws5AMe"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CSvFvjXryPey","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1660892879590,"user_tz":-60,"elapsed":11880,"user":{"displayName":"Brainz1 Sushrut","userId":"09122759057858384343"}},"outputId":"588b09d4-4af3-415e-a7de-d11d109784f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting lightly\n","  Downloading lightly-1.2.27-py3-none-any.whl (480 kB)\n","\u001b[K     |████████████████████████████████| 480 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from lightly) (2.8.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (2.23.0)\n","Collecting lightly-utils~=0.0.0\n","  Downloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.7/dist-packages (from lightly) (57.4.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from lightly) (0.13.1+cu113)\n","Collecting hydra-core>=1.0.0\n","  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 68.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.7/dist-packages (from lightly) (4.64.0)\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.21.6)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.7/dist-packages (from lightly) (2022.6.15)\n","Collecting pytorch-lightning<1.7,>=1.0.4\n","  Downloading pytorch_lightning-1.6.5-py3-none-any.whl (585 kB)\n","\u001b[K     |████████████████████████████████| 585 kB 62.8 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.15.0)\n","Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.7/dist-packages (from lightly) (1.24.3)\n","Collecting omegaconf~=2.2\n","  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.0 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 76.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0.0->lightly) (21.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0.0->lightly) (5.9.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from lightly-utils~=0.0.0->lightly) (7.1.2)\n","Collecting PyYAML>=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 57.1 MB/s \n","\u001b[?25hCollecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n","\u001b[K     |████████████████████████████████| 419 kB 65.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<1.7,>=1.0.4->lightly) (2.8.0)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n","\u001b[K     |████████████████████████████████| 141 kB 75.4 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<1.7,>=1.0.4->lightly) (1.12.1+cu113)\n","Collecting pyDeprecate>=0.3.1\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<1.7,>=1.0.4->lightly) (3.17.3)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<1.7,>=1.0.4->lightly) (4.1.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<1.7,>=1.0.4->lightly) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->hydra-core>=1.0.0->lightly) (3.0.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->lightly) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->lightly) (2.10)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (1.47.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (3.4.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (0.37.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (1.2.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (0.4.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning<1.7,>=1.0.4->lightly) (3.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<1.7,>=1.0.4->lightly) (1.3.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<1.7,>=1.0.4->lightly) (0.13.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<1.7,>=1.0.4->lightly) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<1.7,>=1.0.4->lightly) (1.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<1.7,>=1.0.4->lightly) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<1.7,>=1.0.4->lightly) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<1.7,>=1.0.4->lightly) (2.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning<1.7,>=1.0.4->lightly) (1.8.1)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=5aac5eb39df213f52b34dbcb6fd57ba1ec55d3a2c9f6740c054e603e453c7955\n","  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: PyYAML, fsspec, antlr4-python3-runtime, torchmetrics, pyDeprecate, omegaconf, pytorch-lightning, lightly-utils, hydra-core, lightly\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.9.3 fsspec-2022.7.1 hydra-core-1.2.0 lightly-1.2.27 lightly-utils-0.0.2 omegaconf-2.2.3 pyDeprecate-0.3.2 pytorch-lightning-1.6.5 torchmetrics-0.9.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}],"source":["!pip install lightly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZbwux4E5odO"},"outputs":[],"source":["num_workers = 8\n","batch_size = 128\n","seed = 1\n","epochs = 50\n","input_size = 32\n","\n","# dimension of the embeddings\n","num_ftrs = 512\n","# dimension of the output of the prediction and projection heads\n","out_dim = proj_hidden_dim = 512\n","# the prediction head uses a bottleneck architecture\n","pred_hidden_dim = 128"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kXjBN70cxLBv"},"outputs":[],"source":["import torch\n","from torch import nn\n","import torchvision\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2uIWxzl5Emr"},"outputs":[],"source":["from lightly.data import LightlyDataset\n","from lightly.data import SimCLRCollateFunction\n","from lightly.loss import NegativeCosineSimilarity\n","from lightly.models.modules import BYOLProjectionHead, BYOLPredictionHead\n","from lightly.models.utils import deactivate_requires_grad\n","from lightly.models.utils import update_momentum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y_yEUWs_ya5a"},"outputs":[],"source":["class BYOL(nn.Module):\n","    def __init__(self, backbone):\n","        super().__init__()\n","\n","        self.backbone = backbone\n","        self.projection_head = BYOLProjectionHead(512, 1024, 256)\n","        self.prediction_head = BYOLPredictionHead(256, 1024, 256)\n","\n","        self.backbone_momentum = copy.deepcopy(self.backbone)\n","        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n","\n","        deactivate_requires_grad(self.backbone_momentum)\n","        deactivate_requires_grad(self.projection_head_momentum)\n","\n","    def forward(self, x):\n","        y = self.backbone(x).flatten(start_dim=1)\n","        z = self.projection_head(y)\n","        p = self.prediction_head(z)\n","        return p\n","\n","    def forward_momentum(self, x):\n","        y = self.backbone_momentum(x).flatten(start_dim=1)\n","        z = self.projection_head_momentum(y)\n","        z = z.detach()\n","        return z"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJfoFoVIs11I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660892998092,"user_tz":-60,"elapsed":76985,"user":{"displayName":"Brainz1 Sushrut","userId":"09122759057858384343"}},"outputId":"afa3338f-0941-4ad7-d856-9408435e3cb7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}],"source":["# Note: The model and training settings do not follow the reference settings\n","# from the paper. The settings are chosen such that the example can easily be\n","# run on a small dataset with a single GPU.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","resnet = torchvision.models.resnet18()\n","backbone = nn.Sequential(*list(resnet.children())[:-1])\n","model = BYOL(backbone)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)\n","\n","#cifar10 = torchvision.datasets.CIFAR10(\"datasets/cifar10\", download=True)\n","#dataset = LightlyDataset.from_torch_dataset(cifar10)\n","# or create a dataset from a folder containing images or videos:\n","dataset = LightlyDataset(\"/content/drive/MyDrive/Project/Dataset/train_byol\")\n","\n","collate_fn = SimCLRCollateFunction(input_size=32)\n","\n","dataloader = torch.utils.data.DataLoader(\n","    dataset,\n","    batch_size=256,\n","    collate_fn=collate_fn,\n","    shuffle=True,\n","    drop_last=True,\n","    num_workers=8,\n",")\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_F6wXax0QvQt"},"outputs":[],"source":["criterion = NegativeCosineSimilarity()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.06)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z38U1otbtke7","outputId":"cdb7f13a-5027-4758-f129-d0493fb8337f","executionInfo":{"status":"ok","timestamp":1660896052749,"user_tz":-60,"elapsed":3054661,"user":{"displayName":"Brainz1 Sushrut","userId":"09122759057858384343"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Training\n","epoch: 00, loss: -0.52850\n","epoch: 01, loss: -0.62298\n","epoch: 02, loss: -0.68073\n","epoch: 03, loss: -0.72203\n","epoch: 04, loss: -0.74687\n","epoch: 05, loss: -0.76530\n","epoch: 06, loss: -0.77816\n","epoch: 07, loss: -0.78930\n","epoch: 08, loss: -0.79690\n","epoch: 09, loss: -0.80072\n","epoch: 10, loss: -0.81112\n","epoch: 11, loss: -0.81733\n","epoch: 12, loss: -0.82567\n","epoch: 13, loss: -0.82956\n","epoch: 14, loss: -0.83360\n","epoch: 15, loss: -0.83420\n","epoch: 16, loss: -0.84078\n","epoch: 17, loss: -0.83964\n","epoch: 18, loss: -0.84058\n","epoch: 19, loss: -0.84701\n","epoch: 20, loss: -0.84681\n","epoch: 21, loss: -0.85310\n","epoch: 22, loss: -0.85380\n","epoch: 23, loss: -0.85391\n","epoch: 24, loss: -0.85519\n"]}],"source":["print(\"Starting Training\")\n","for epoch in range(25):\n","    total_loss = 0\n","    for (x0, x1), _, _ in dataloader:\n","        update_momentum(model.backbone, model.backbone_momentum, m=0.99)\n","        update_momentum(model.projection_head, model.projection_head_momentum, m=0.99)\n","        x0 = x0.to(device)\n","        x1 = x1.to(device)\n","        p0 = model(x0)\n","        z0 = model.forward_momentum(x0)\n","        p1 = model(x1)\n","        z1 = model.forward_momentum(x1)\n","        loss = 0.5 * (criterion(p0, z1) + criterion(p1, z0))\n","        total_loss += loss.detach()\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    avg_loss = total_loss / len(dataloader)\n","    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"ZDpBz6hcQ1ys","executionInfo":{"status":"ok","timestamp":1660896314767,"user_tz":-60,"elapsed":245,"user":{"displayName":"Brainz1 Sushrut","userId":"09122759057858384343"}}},"outputs":[],"source":["pretrained_resnet_backbone = model.backbone\n","\n","# you can also store the backbone and use it in another code\n","state_dict = {\n","    'resnet18_parameters': pretrained_resnet_backbone.state_dict()\n","}\n","torch.save(state_dict, '/content/drive/MyDrive/Project/Models/BYOL_MODELS/BYOL(85,25EPOCHS,lr=0.06)model.pth')"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":530,"status":"ok","timestamp":1660896334508,"user":{"displayName":"Brainz1 Sushrut","userId":"09122759057858384343"},"user_tz":-60},"id":"qwQFw8W-Q31u","outputId":"16f9dba8-c9a6-4417-efee-a31558bc7ab6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":24}],"source":["# load the model in a new file for inference\n","resnet18_new = torchvision.models.resnet18()\n","\n","# note that we need to create exactly the same backbone in order to load the weights\n","backbone_new = nn.Sequential(*list(resnet18_new.children())[:-1])\n","\n","ckpt = torch.load('/content/drive/MyDrive/Project/Models/BYOL_MODELS/BYOL(85,25EPOCHS,lr=0.06)model.pth')\n","backbone_new.load_state_dict(ckpt['resnet18_parameters'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1660896054077,"user":{"displayName":"Brainz1 Sushrut","userId":"09122759057858384343"},"user_tz":-60},"id":"evQ6gvSPS3Nt","outputId":"b6010bb7-b596-4f18-b67c-de19f329bf18"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BYOL(\n","  (backbone): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (projection_head): BYOLProjectionHead(\n","    (layers): Sequential(\n","      (0): Linear(in_features=512, out_features=1024, bias=False)\n","      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): Linear(in_features=1024, out_features=256, bias=True)\n","    )\n","  )\n","  (prediction_head): BYOLPredictionHead(\n","    (layers): Sequential(\n","      (0): Linear(in_features=256, out_features=1024, bias=False)\n","      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): Linear(in_features=1024, out_features=256, bias=True)\n","    )\n","  )\n","  (backbone_momentum): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (5): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (6): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (7): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n","  )\n","  (projection_head_momentum): BYOLProjectionHead(\n","    (layers): Sequential(\n","      (0): Linear(in_features=512, out_features=1024, bias=False)\n","      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): Linear(in_features=1024, out_features=256, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":10}],"source":["model = BYOL(backbone_new)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"id":"Qmg0iobAS8OV","executionInfo":{"status":"ok","timestamp":1660896054080,"user_tz":-60,"elapsed":32,"user":{"displayName":"Brainz1 Sushrut","userId":"09122759057858384343"}},"outputId":"23b1df0b-e4a7-436c-de55-ca1f7643970e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'print(\"Starting Training\")\\nfor epoch in range(20):\\n    total_loss = 0\\n    for (x0, x1), _, _ in dataloader:\\n        update_momentum(model.backbone, model.backbone_momentum, m=0.99)\\n        update_momentum(model.projection_head, model.projection_head_momentum, m=0.99)\\n        x0 = x0.to(device)\\n        x1 = x1.to(device)\\n        p0 = model(x0)\\n        z0 = model.forward_momentum(x0)\\n        p1 = model(x1)\\n        z1 = model.forward_momentum(x1)\\n        loss = 0.5 * (criterion(p0, z1) + criterion(p1, z0))\\n        total_loss += loss.detach()\\n        loss.backward()\\n        optimizer.step()\\n        optimizer.zero_grad()\\n    avg_loss = total_loss / len(dataloader)\\n    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["'''print(\"Starting Training\")\n","for epoch in range(20):\n","    total_loss = 0\n","    for (x0, x1), _, _ in dataloader:\n","        update_momentum(model.backbone, model.backbone_momentum, m=0.99)\n","        update_momentum(model.projection_head, model.projection_head_momentum, m=0.99)\n","        x0 = x0.to(device)\n","        x1 = x1.to(device)\n","        p0 = model(x0)\n","        z0 = model.forward_momentum(x0)\n","        p1 = model(x1)\n","        z1 = model.forward_momentum(x1)\n","        loss = 0.5 * (criterion(p0, z1) + criterion(p1, z0))\n","        total_loss += loss.detach()\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","    avg_loss = total_loss / len(dataloader)\n","    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FPDl9mHeRInj"},"outputs":[],"source":["import lightly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k8dzoHfW5fhq"},"outputs":[],"source":["test_transforms = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize((input_size, input_size)),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize(\n","        mean=lightly.data.collate.imagenet_normalize['mean'],\n","        std=lightly.data.collate.imagenet_normalize['std'],\n","    )\n","])\n","\n","# create a lightly dataset for embedding\n","dataset_test = lightly.data.LightlyDataset(\n","    input_dir=\"/content/drive/MyDrive/Project/Dataset/train_byol\",\n","    transform=test_transforms\n",")\n","\n","# create a dataloader for embedding\n","dataloader_test = torch.utils.data.DataLoader(\n","    dataset_test,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    drop_last=False,\n","    num_workers=num_workers\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tU3OQWfNuiF3"},"outputs":[],"source":["\n","embeddings = []\n","filenames = []\n","\n","# disable gradients for faster calculations\n","model.eval()\n","with torch.no_grad():\n","    for i, (x, _, fnames) in enumerate(dataloader_test):\n","        # move the images to the gpu\n","        x = x.to(device)\n","        # embed the images with the pre-trained backbone\n","        y = model.backbone(x).flatten(start_dim=1)\n","        # store the embeddings and filenames in lists\n","        embeddings.append(y)\n","        filenames = filenames + list(fnames)\n","\n","# concatenate the embeddings and convert to numpy\n","embeddings = torch.cat(embeddings, dim=0)\n","embeddings = embeddings.cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wKzq9rzGv856"},"outputs":[],"source":["# for plotting\n","import os\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.offsetbox as osb\n","from matplotlib import rcParams as rcp\n","\n","# for resizing images to thumbnails\n","import torchvision.transforms.functional as functional\n","\n","# for clustering and 2d representations\n","from sklearn import random_projection"]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"nceP8qBsIEGa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VfLfhilWupnX"},"outputs":[],"source":["# for the scatter plot we want to transform the images to a two-dimensional\n","# vector space using a random Gaussian projection\n","projection = random_projection.GaussianRandomProjection(n_components=2)\n","embeddings_2d = projection.fit_transform(embeddings)\n","\n","# normalize the embeddings to fit in the [0, 1] square\n","M = np.max(embeddings_2d, axis=0)\n","m = np.min(embeddings_2d, axis=0)\n","embeddings_2d = (embeddings_2d - m) / (M - m)"]},{"cell_type":"code","source":["def get_scatter_plot_with_thumbnails():\n","    \"\"\"Creates a scatter plot with image overlays.\n","    \"\"\"\n","    # initialize empty figure and add subplot\n","    fig = plt.figure()\n","    fig.suptitle('Scatter Plot of the Sentinel-2 Dataset')\n","    ax = fig.add_subplot(1, 1, 1)\n","    # shuffle images and find out which images to show\n","    shown_images_idx = []\n","    shown_images = np.array([[1., 1.]])\n","    iterator = [i for i in range(embeddings_2d.shape[0])]\n","    np.random.shuffle(iterator)\n","    for i in iterator:\n","        # only show image if it is sufficiently far away from the others\n","        dist = np.sum((embeddings_2d[i] - shown_images) ** 2, 1)\n","        if np.min(dist) < 2e-3:\n","            continue\n","        shown_images = np.r_[shown_images, [embeddings_2d[i]]]\n","        shown_images_idx.append(i)\n","\n","    # plot image overlays\n","    for idx in shown_images_idx:\n","        thumbnail_size = int(rcp['figure.figsize'][0] * 2.)\n","        path = os.path.join('/content/drive/MyDrive/Project/Dataset/train_byol', filenames[idx])\n","        img = Image.open(path)\n","        img = functional.resize(img, thumbnail_size)\n","        img = np.array(img)\n","        img_box = osb.AnnotationBbox(\n","            osb.OffsetImage(img, cmap=plt.cm.gray_r),\n","            embeddings_2d[idx],\n","            pad=0.2,\n","        )\n","        ax.add_artist(img_box)\n","\n","    # set aspect ratio\n","    ratio = 1. / ax.get_data_ratio()\n","    ax.set_aspect(ratio, adjustable='box')\n","\n","\n","# get a scatter plot with thumbnail overlays\n","get_scatter_plot_with_thumbnails()"],"metadata":{"id":"bXmlYBsPBr14","colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"status":"error","timestamp":1660896260792,"user_tz":-60,"elapsed":343,"user":{"displayName":"Brainz1 Sushrut","userId":"09122759057858384343"}},"outputId":"c53e05b3-b52a-4abe-8ae5-9727d84515de"},"execution_count":22,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-617924f96e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# get a scatter plot with thumbnail overlays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mget_scatter_plot_with_thumbnails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-617924f96e3f>\u001b[0m in \u001b[0;36mget_scatter_plot_with_thumbnails\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# initialize empty figure and add subplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scatter Plot of the Sentinel-2 Dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m                                         \u001b[0mframeon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                                         \u001b[0mFigureClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFigureClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfigLabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[0;34m(cls, num, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m         \u001b[0mfig_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FigureClass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3357\u001b[0;31m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_figure_manager_given_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, figsize, dpi, facecolor, edgecolor, linewidth, frameon, subplotpars, tight_layout, constrained_layout)\u001b[0m\n\u001b[1;32m    349\u001b[0m             raise ValueError('figure size must be positive finite not '\n\u001b[1;32m    350\u001b[0m                              f'{figsize}')\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi_scale_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAffine2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: from_bounds() argument after * must be an iterable, not int"]}]}],"metadata":{"accelerator":"GPU","colab":{"name":"Training_BYOL.ipynb","provenance":[],"mount_file_id":"1MeMHVSxa2_VMKsJM9ov-LRiiq-BN5L4_","authorship_tag":"ABX9TyNpMcReMF3PRecyV6qtlqHI"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}